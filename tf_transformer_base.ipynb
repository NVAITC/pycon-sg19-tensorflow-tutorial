{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==2.0 tensorflow_datasets gpustat transformers -Uq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About**\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/6/6d/Nvidia_image_logo.svg/200px-Nvidia_image_logo.svg.png\" width=\"90px\" align=\"right\" style=\"margin-right: 0px;\">\n",
    "\n",
    "This notebook is put together by Timothy Liu (`timothyl@nvidia.com`) for the [**PyCon SG**](https://pycon.sg/) 2019 tutorial on [**Improving Deep Learning Performance in TensorFlow**](https://github.com/NVAITC/pycon-sg19-tensorflow-tutorial).\n",
    "\n",
    "**Acknowledgements**\n",
    "\n",
    "* This notebook uses some materials adapted from TensorFlow documentation.\n",
    "* This notebook uses the [HuggingFace Transformers library](https://github.com/huggingface/transformers).\n",
    "* This notebook uses the [GLUE (MRPC) Dataset](https://gluebenchmark.com/) ([TensorFlow Datasets page](https://www.tensorflow.org/datasets/catalog/glue)).\n",
    "\n",
    "**Dataset Citation**\n",
    "\n",
    "```\n",
    "@inproceedings{wang2019glue,\n",
    "  title={ {GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n",
    "  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n",
    "  note={In the Proceedings of ICLR.},\n",
    "  year={2019}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Classification with BERT in TF 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 13:59:37.196684 140047702144832 file_utils.py:32] TensorFlow version 2.0.0 available.\n",
      "I1011 13:59:38.532777 140047702144832 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/jovyan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification, glue_convert_examples_to_features\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 13:59:38.577600 140047702144832 dataset_builder.py:184] Overwrite dataset info from restored data version.\n",
      "I1011 13:59:38.583055 140047702144832 dataset_builder.py:253] Reusing dataset glue (/home/jovyan/tensorflow_datasets/glue/mrpc/0.0.2)\n",
      "I1011 13:59:38.584074 140047702144832 dataset_builder.py:399] Constructing tf.data.Dataset for split None, from /home/jovyan/tensorflow_datasets/glue/mrpc/0.0.2\n",
      "W1011 13:59:41.050402 140047702144832 dataset_builder.py:439] Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "data, info = tensorflow_datasets.load(\"glue/mrpc\", with_info=True)\n",
    "\n",
    "train_examples = info.splits[\"train\"].num_examples\n",
    "valid_examples = info.splits[\"validation\"].num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 13:59:41.128844 140047702144832 glue.py:70] Using label list ['0', '1'] for task mrpc\n",
      "I1011 13:59:41.130121 140047702144832 glue.py:73] Using output mode classification for task mrpc\n",
      "I1011 13:59:41.176858 140047702144832 glue.py:80] Writing example 0\n",
      "I1011 13:59:41.180326 140047702144832 glue.py:119] *** Example ***\n",
      "I1011 13:59:41.181278 140047702144832 glue.py:120] guid: 201\n",
      "I1011 13:59:41.182255 140047702144832 glue.py:121] input_ids: 101 157 13292 2528 1144 1215 1103 16513 15125 11944 1271 1290 1898 1111 1317 1104 1157 2815 2982 117 2452 1106 1103 19585 2858 17762 117 1756 1419 119 102 157 13292 2528 1144 1215 1103 16513 15125 11944 1271 1290 1898 1111 1317 1104 1157 2815 2982 117 1122 1163 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.183290 140047702144832 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.184182 140047702144832 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.185057 140047702144832 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:59:41.189723 140047702144832 glue.py:119] *** Example ***\n",
      "I1011 13:59:41.190629 140047702144832 glue.py:120] guid: 2977\n",
      "I1011 13:59:41.191365 140047702144832 glue.py:121] input_ids: 101 2082 1104 1103 6351 22620 10951 1116 4349 1107 10258 16564 1137 1260 17046 5660 117 1163 7796 2159 117 6998 112 188 2682 23659 1105 1704 12654 119 102 107 23665 1306 3520 1185 6641 117 107 1163 7796 2159 117 6998 112 188 2682 4711 118 2084 1105 1704 12654 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.192003 140047702144832 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.192615 140047702144832 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.193188 140047702144832 glue.py:124] label: 0 (id = 0)\n",
      "I1011 13:59:41.196016 140047702144832 glue.py:119] *** Example ***\n",
      "I1011 13:59:41.196642 140047702144832 glue.py:120] guid: 3482\n",
      "I1011 13:59:41.197273 140047702144832 glue.py:121] input_ids: 101 21997 117 6036 2103 2588 1207 16565 117 4362 1103 1703 1295 1104 2740 1106 3746 1604 119 102 1109 2248 2103 1330 2588 16950 2740 8128 117 1781 1157 1703 1106 3746 1604 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.197922 140047702144832 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.198554 140047702144832 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.199115 140047702144832 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:59:41.202093 140047702144832 glue.py:119] *** Example ***\n",
      "I1011 13:59:41.202721 140047702144832 glue.py:120] guid: 1187\n",
      "I1011 13:59:41.203365 140047702144832 glue.py:121] input_ids: 101 138 2370 2403 117 1103 7873 1951 3555 1115 14781 1125 4215 1120 170 128 119 123 3029 2603 1107 1103 1503 3861 119 102 138 2370 2403 117 1103 7873 1951 1163 14781 2580 1120 170 128 119 123 3029 2603 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.203997 140047702144832 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.204661 140047702144832 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.205231 140047702144832 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:59:41.208313 140047702144832 glue.py:119] *** Example ***\n",
      "I1011 13:59:41.208932 140047702144832 glue.py:120] guid: 1220\n",
      "I1011 13:59:41.209564 140047702144832 glue.py:121] input_ids: 101 23166 1850 170 2998 1106 5957 1697 8521 5148 5710 4107 1111 170 3009 3189 1137 170 6187 20737 4027 119 102 3215 1305 2341 4284 5316 23166 3010 170 2998 5286 1106 5957 4552 1697 8521 5148 5710 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.210203 140047702144832 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.210818 140047702144832 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:41.211380 140047702144832 glue.py:124] label: 0 (id = 0)\n",
      "I1011 13:59:45.574368 140047702144832 glue.py:70] Using label list ['0', '1'] for task mrpc\n",
      "I1011 13:59:45.575383 140047702144832 glue.py:73] Using output mode classification for task mrpc\n",
      "I1011 13:59:45.614118 140047702144832 glue.py:80] Writing example 0\n",
      "I1011 13:59:45.616382 140047702144832 glue.py:119] *** Example ***\n",
      "I1011 13:59:45.617535 140047702144832 glue.py:120] guid: 657\n",
      "I1011 13:59:45.618774 140047702144832 glue.py:121] input_ids: 101 1284 5376 1272 1195 1486 1103 3685 2554 1107 170 1207 1609 117 1194 1103 185 18502 1104 1412 2541 1113 1429 1347 117 107 155 17167 7355 1163 119 102 11056 117 1103 1646 5376 1272 1103 3469 1486 107 3685 2554 1107 170 1207 1609 117 1194 1103 185 18502 1104 1412 2541 1113 1347 1429 107 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.619963 140047702144832 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.620799 140047702144832 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.621568 140047702144832 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:59:45.626282 140047702144832 glue.py:119] *** Example ***\n",
      "I1011 13:59:45.627102 140047702144832 glue.py:120] guid: 2223\n",
      "I1011 13:59:45.627720 140047702144832 glue.py:121] input_ids: 101 2061 117 1150 1125 3421 16042 4290 1121 1201 1104 1344 1892 2997 117 1452 1120 14157 1116 118 22986 3875 1945 1213 130 131 1476 170 119 182 119 117 1163 2618 13105 20642 27776 119 102 2061 117 1150 1125 16042 4290 1121 1201 1104 1344 1892 2997 117 1125 1151 15819 17693 6834 1548 1105 1125 1151 2704 2200 1290 170 1347 6625 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.628309 140047702144832 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.628870 140047702144832 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.629396 140047702144832 glue.py:124] label: 0 (id = 0)\n",
      "I1011 13:59:45.632586 140047702144832 glue.py:119] *** Example ***\n",
      "I1011 13:59:45.633162 140047702144832 glue.py:120] guid: 2551\n",
      "I1011 13:59:45.633752 140047702144832 glue.py:121] input_ids: 101 1130 1103 8448 1692 117 11336 7272 19854 1163 1103 1329 1104 1886 1108 1136 107 11982 24423 107 1106 5515 1103 2755 112 188 14043 2199 1107 9531 119 102 11336 7272 19854 1724 1115 1103 1449 1108 1136 11982 24423 1106 5515 1103 2199 1107 4339 9531 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.634346 140047702144832 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.634949 140047702144832 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.635457 140047702144832 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:59:45.638217 140047702144832 glue.py:119] *** Example ***\n",
      "I1011 13:59:45.638792 140047702144832 glue.py:120] guid: 366\n",
      "I1011 13:59:45.639373 140047702144832 glue.py:121] input_ids: 101 1335 1661 7632 117 17185 1209 5152 1106 109 123 117 4645 1121 109 123 117 2260 119 102 3704 2134 1651 1209 1267 1147 17185 3606 1118 109 3127 1106 109 123 117 4645 1137 1367 3029 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.639948 140047702144832 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.640497 140047702144832 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.640996 140047702144832 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:59:45.643532 140047702144832 glue.py:119] *** Example ***\n",
      "I1011 13:59:45.644069 140047702144832 glue.py:120] guid: 416\n",
      "I1011 13:59:45.644624 140047702144832 glue.py:121] input_ids: 101 107 6983 112 188 170 1363 2564 117 107 16785 1163 117 5321 131 107 6983 1110 1690 1103 4185 1297 1104 1103 1203 1365 8765 119 102 1124 1145 1163 18000 2254 1110 107 1690 1103 4185 1297 1104 170 1203 1365 8765 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.645167 140047702144832 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.645692 140047702144832 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:59:45.646212 140047702144832 glue.py:124] label: 0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 40\n",
    "\n",
    "# Prepare dataset for GLUE as a tf.data.Dataset instance\n",
    "train_dataset = glue_convert_examples_to_features(data[\"train\"], tokenizer, 128, \"mrpc\")\n",
    "train_dataset = train_dataset.shuffle(512).batch(BATCH_SIZE).repeat(-1)\n",
    "\n",
    "valid_dataset = glue_convert_examples_to_features(data[\"validation\"], tokenizer, 128, \"mrpc\")\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 13:59:47.151864 140047702144832 configuration_utils.py:150] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/jovyan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1011 13:59:47.153718 140047702144832 configuration_utils.py:167] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1011 13:59:48.129096 140047702144832 modeling_tf_utils.py:256] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-tf_model.h5 from cache at /home/jovyan/.cache/torch/transformers/54c7ddffbd4d74d7592fac0cca93a6542cfee71482507625c277ddd4c6b7d41c.908e74db1113031d6827eb22808cf370b0aeded6e6ac20d0f07af0a334e195cc.h5\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
    "model.compile(optimizer=opt,\n",
    "              loss=loss,\n",
    "              metrics=[acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_callback = TimeHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 91 steps, validate for 10 steps\n",
      "Epoch 1/4\n",
      "91/91 [==============================] - 52s 575ms/step - loss: 0.6012 - accuracy: 0.6717\n",
      "Epoch 2/4\n",
      "91/91 [==============================] - 32s 353ms/step - loss: 0.4223 - accuracy: 0.8104\n",
      "Epoch 3/4\n",
      "91/91 [==============================] - 37s 402ms/step - loss: 0.2022 - accuracy: 0.9242 - val_loss: 0.4714 - val_accuracy: 0.8550\n",
      "Epoch 4/4\n",
      "91/91 [==============================] - 32s 353ms/step - loss: 0.0913 - accuracy: 0.9655\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=4, steps_per_epoch=train_examples//BATCH_SIZE,\n",
    "                    validation_data=valid_dataset, validation_steps=valid_examples//BATCH_SIZE,\n",
    "                    validation_freq=3, callbacks=[time_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Examples/s: 114.0\n"
     ]
    }
   ],
   "source": [
    "epoch_time = min(time_callback.times)\n",
    "egs_per_sec = train_examples//epoch_time\n",
    "\n",
    "print(\"Peak Examples/s:\", egs_per_sec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
