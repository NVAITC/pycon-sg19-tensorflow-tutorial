{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"tf_transformer_base.ipynb","provenance":[],"collapsed_sections":["UqslZYH8mhNU"],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UqslZYH8mhNU","colab_type":"text"},"source":["## Setup\n","\n","This section contains supplementary information, functions, and installs required packages."]},{"cell_type":"code","metadata":{"id":"gss2_uX1mhNV","colab_type":"code","colab":{}},"source":["!pip install tensorflow-gpu==2.0 tensorflow_datasets gpustat transformers -Uq"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8hPa-QqumhNY","colab_type":"text"},"source":["**About**\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/6/6d/Nvidia_image_logo.svg/200px-Nvidia_image_logo.svg.png\" width=\"90px\" align=\"right\" style=\"margin-right: 0px;\">\n","\n","This notebook is put together by Timothy Liu (`timothyl@nvidia.com`) for the [**PyCon SG**](https://pycon.sg/) 2019 tutorial on [**Improving Deep Learning Performance in TensorFlow**](https://github.com/NVAITC/pycon-sg19-tensorflow-tutorial).\n","\n","**Acknowledgements**\n","\n","* This notebook uses some materials adapted from TensorFlow documentation.\n","* This notebook uses the [HuggingFace Transformers library](https://github.com/huggingface/transformers).\n","* This notebook uses the [GLUE (MRPC) Dataset](https://gluebenchmark.com/) ([TensorFlow Datasets page](https://www.tensorflow.org/datasets/catalog/glue)).\n","\n","**Dataset Citation**\n","\n","```\n","@inproceedings{wang2019glue,\n","  title={ {GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n","  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n","  note={In the Proceedings of ICLR.},\n","  year={2019}\n","}\n","```"]},{"cell_type":"code","metadata":{"id":"5RTQHdpNmhNY","colab_type":"code","colab":{}},"source":["import tensorflow.compat.v2 as tf\n","import tensorflow_datasets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wm5qQqiLmhNa","colab_type":"code","colab":{}},"source":["import time\n","\n","class TimeHistory(tf.keras.callbacks.Callback):\n","    def on_train_begin(self, logs={}):\n","        self.times = []\n","    def on_epoch_begin(self, epoch, logs={}):\n","        self.epoch_time_start = time.time()\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.times.append(time.time() - self.epoch_time_start)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5DMm-1HmmhNc","colab_type":"text"},"source":["# Sequence Classification with BERT in TF 2.0"]},{"cell_type":"code","metadata":{"id":"ZM4spGMNp5wN","colab_type":"code","colab":{}},"source":["!gpustat"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WkWHOum3mhNe","colab_type":"text"},"source":["## Load BERT Tokenizer"]},{"cell_type":"code","metadata":{"id":"qqd1X8dxmhNf","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"imu1KLWvmhNh","colab_type":"text"},"source":["## Input Pipeline"]},{"cell_type":"markdown","metadata":{"id":"nFFtBf6amhNh","colab_type":"text"},"source":["### Load Dataset"]},{"cell_type":"code","metadata":{"id":"WUAUMzVOmhNi","colab_type":"code","outputId":"40288796-f303-4af9-e905-40f3349c6d94","colab":{}},"source":["data, info = tensorflow_datasets.load(\"glue/mrpc\", with_info=True)\n","\n","train_examples = info.splits[\"train\"].num_examples\n","valid_examples = info.splits[\"validation\"].num_examples"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:absl:Overwrite dataset info from restored data version.\n","INFO:absl:Reusing dataset glue (/home/jovyan/tensorflow_datasets/glue/mrpc/0.0.2)\n","INFO:absl:Constructing tf.data.Dataset for split None, from /home/jovyan/tensorflow_datasets/glue/mrpc/0.0.2\n","WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"LTZECdgxmhNl","colab_type":"text"},"source":["## Build Input Pipeline"]},{"cell_type":"code","metadata":{"id":"eBkLtX9bmhNl","colab_type":"code","colab":{}},"source":["from transformers import glue_convert_examples_to_features\n","\n","BATCH_SIZE = 32\n","\n","# Prepare dataset for GLUE as a tf.data.Dataset instance\n","train_dataset = glue_convert_examples_to_features(data[\"train\"], tokenizer, 128, \"mrpc\")\n","train_dataset = train_dataset.shuffle(512).batch(BATCH_SIZE).repeat(-1)\n","\n","valid_dataset = glue_convert_examples_to_features(data[\"validation\"], tokenizer, 128, \"mrpc\")\n","valid_dataset = valid_dataset.batch(BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vC_qPDcjmhNn","colab_type":"text"},"source":["## Build BERT Model"]},{"cell_type":"markdown","metadata":{"id":"3sAKlIGPmhNo","colab_type":"text"},"source":["### Load Pre-trained BERT Model"]},{"cell_type":"code","metadata":{"id":"vW2d3lctmhNo","colab_type":"code","colab":{}},"source":["from transformers import TFBertForSequenceClassification\n","\n","model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k2qMgxExmhNq","colab_type":"code","colab":{}},"source":["opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n","\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","acc = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n","model.compile(optimizer=opt,\n","              loss=loss,\n","              metrics=[acc])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gNhNvzncmhNs","colab_type":"text"},"source":["## Train BERT Model"]},{"cell_type":"code","metadata":{"id":"it4pTXFAmhNt","colab_type":"code","colab":{}},"source":["time_callback = TimeHistory()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWyY0SJHmhNu","colab_type":"code","outputId":"3fe4f64c-8eff-463f-9367-877abf335699","colab":{}},"source":["history = model.fit(train_dataset, epochs=4, steps_per_epoch=train_examples//BATCH_SIZE,\n","                    validation_data=valid_dataset, validation_steps=valid_examples//BATCH_SIZE,\n","                    validation_freq=3, callbacks=[time_callback])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train for 114 steps, validate for 12 steps\n","Epoch 1/4\n","114/114 [==============================] - 116s 1s/step - loss: 0.5787 - accuracy: 0.7182\n","Epoch 2/4\n","114/114 [==============================] - 94s 828ms/step - loss: 0.3521 - accuracy: 0.8490\n","Epoch 3/4\n","114/114 [==============================] - 101s 886ms/step - loss: 0.1301 - accuracy: 0.9574 - val_loss: 0.4803 - val_accuracy: 0.8385\n","Epoch 4/4\n","114/114 [==============================] - 94s 828ms/step - loss: 0.0507 - accuracy: 0.9854\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IFXITNKamhNy","colab_type":"code","outputId":"ea9c70b0-adfe-4c34-cd01-69aca772ae8e","colab":{}},"source":["epoch_time = min(time_callback.times)\n","egs_per_sec = train_examples//epoch_time\n","\n","print(\"Peak Examples/s:\", egs_per_sec)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Peak Examples/s: 38.0\n"],"name":"stdout"}]}]}