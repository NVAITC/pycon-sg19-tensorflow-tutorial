{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==2.0 tensorflow_datasets gpustat transformers -Uq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About**\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/6/6d/Nvidia_image_logo.svg/200px-Nvidia_image_logo.svg.png\" width=\"90px\" align=\"right\" style=\"margin-right: 0px;\">\n",
    "\n",
    "This notebook is put together by Timothy Liu (`timothyl@nvidia.com`) for the [**PyCon SG**](https://pycon.sg/) 2019 tutorial on [**Improving Deep Learning Performance in TensorFlow**](https://github.com/NVAITC/pycon-sg19-tensorflow-tutorial).\n",
    "\n",
    "**Acknowledgements**\n",
    "\n",
    "* This notebook uses some materials adapted from TensorFlow documentation.\n",
    "* This notebook uses the [HuggingFace Transformers library](https://github.com/huggingface/transformers).\n",
    "* This notebook uses the [GLUE (MRPC) Dataset](https://gluebenchmark.com/) ([TensorFlow Datasets page](https://www.tensorflow.org/datasets/catalog/glue)).\n",
    "\n",
    "**Dataset Citation**\n",
    "\n",
    "```\n",
    "@inproceedings{wang2019glue,\n",
    "  title={ {GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n",
    "  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n",
    "  note={In the Proceedings of ICLR.},\n",
    "  year={2019}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Classification with BERT in TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable XLA\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# enable AMP\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 13:52:47.972529 140334737692480 file_utils.py:32] TensorFlow version 2.0.0 available.\n",
      "I1011 13:52:49.337029 140334737692480 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/jovyan/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification, glue_convert_examples_to_features\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 13:52:49.385582 140334737692480 dataset_builder.py:184] Overwrite dataset info from restored data version.\n",
      "I1011 13:52:49.390514 140334737692480 dataset_builder.py:253] Reusing dataset glue (/home/jovyan/tensorflow_datasets/glue/mrpc/0.0.2)\n",
      "I1011 13:52:49.391412 140334737692480 dataset_builder.py:399] Constructing tf.data.Dataset for split None, from /home/jovyan/tensorflow_datasets/glue/mrpc/0.0.2\n",
      "W1011 13:52:51.585335 140334737692480 dataset_builder.py:439] Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "data, info = tensorflow_datasets.load(\"glue/mrpc\", with_info=True)\n",
    "\n",
    "train_examples = info.splits[\"train\"].num_examples\n",
    "valid_examples = info.splits[\"validation\"].num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 13:52:51.667015 140334737692480 glue.py:70] Using label list ['0', '1'] for task mrpc\n",
      "I1011 13:52:51.668042 140334737692480 glue.py:73] Using output mode classification for task mrpc\n",
      "I1011 13:52:51.715626 140334737692480 glue.py:80] Writing example 0\n",
      "I1011 13:52:51.718473 140334737692480 glue.py:119] *** Example ***\n",
      "I1011 13:52:51.719347 140334737692480 glue.py:120] guid: 2977\n",
      "I1011 13:52:51.720160 140334737692480 glue.py:121] input_ids: 101 2082 1104 1103 6351 22620 10951 1116 4349 1107 10258 16564 1137 1260 17046 5660 117 1163 7796 2159 117 6998 112 188 2682 23659 1105 1704 12654 119 102 107 23665 1306 3520 1185 6641 117 107 1163 7796 2159 117 6998 112 188 2682 4711 118 2084 1105 1704 12654 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.721060 140334737692480 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.721862 140334737692480 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.722705 140334737692480 glue.py:124] label: 0 (id = 0)\n",
      "I1011 13:52:51.726876 140334737692480 glue.py:119] *** Example ***\n",
      "I1011 13:52:51.727671 140334737692480 glue.py:120] guid: 201\n",
      "I1011 13:52:51.728338 140334737692480 glue.py:121] input_ids: 101 157 13292 2528 1144 1215 1103 16513 15125 11944 1271 1290 1898 1111 1317 1104 1157 2815 2982 117 2452 1106 1103 19585 2858 17762 117 1756 1419 119 102 157 13292 2528 1144 1215 1103 16513 15125 11944 1271 1290 1898 1111 1317 1104 1157 2815 2982 117 1122 1163 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.729017 140334737692480 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.729658 140334737692480 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.730411 140334737692480 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:52:51.733202 140334737692480 glue.py:119] *** Example ***\n",
      "I1011 13:52:51.733810 140334737692480 glue.py:120] guid: 3482\n",
      "I1011 13:52:51.734563 140334737692480 glue.py:121] input_ids: 101 21997 117 6036 2103 2588 1207 16565 117 4362 1103 1703 1295 1104 2740 1106 3746 1604 119 102 1109 2248 2103 1330 2588 16950 2740 8128 117 1781 1157 1703 1106 3746 1604 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.735197 140334737692480 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.735813 140334737692480 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.736379 140334737692480 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:52:51.739442 140334737692480 glue.py:119] *** Example ***\n",
      "I1011 13:52:51.740051 140334737692480 glue.py:120] guid: 1187\n",
      "I1011 13:52:51.740668 140334737692480 glue.py:121] input_ids: 101 138 2370 2403 117 1103 7873 1951 3555 1115 14781 1125 4215 1120 170 128 119 123 3029 2603 1107 1103 1503 3861 119 102 138 2370 2403 117 1103 7873 1951 1163 14781 2580 1120 170 128 119 123 3029 2603 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.741281 140334737692480 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.741928 140334737692480 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.742556 140334737692480 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:52:51.745498 140334737692480 glue.py:119] *** Example ***\n",
      "I1011 13:52:51.746204 140334737692480 glue.py:120] guid: 1220\n",
      "I1011 13:52:51.746855 140334737692480 glue.py:121] input_ids: 101 23166 1850 170 2998 1106 5957 1697 8521 5148 5710 4107 1111 170 3009 3189 1137 170 6187 20737 4027 119 102 3215 1305 2341 4284 5316 23166 3010 170 2998 5286 1106 5957 4552 1697 8521 5148 5710 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.747488 140334737692480 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.748142 140334737692480 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:51.748749 140334737692480 glue.py:124] label: 0 (id = 0)\n",
      "I1011 13:52:56.061424 140334737692480 glue.py:70] Using label list ['0', '1'] for task mrpc\n",
      "I1011 13:52:56.062580 140334737692480 glue.py:73] Using output mode classification for task mrpc\n",
      "I1011 13:52:56.101993 140334737692480 glue.py:80] Writing example 0\n",
      "I1011 13:52:56.107114 140334737692480 glue.py:119] *** Example ***\n",
      "I1011 13:52:56.108122 140334737692480 glue.py:120] guid: 657\n",
      "I1011 13:52:56.109152 140334737692480 glue.py:121] input_ids: 101 1284 5376 1272 1195 1486 1103 3685 2554 1107 170 1207 1609 117 1194 1103 185 18502 1104 1412 2541 1113 1429 1347 117 107 155 17167 7355 1163 119 102 11056 117 1103 1646 5376 1272 1103 3469 1486 107 3685 2554 1107 170 1207 1609 117 1194 1103 185 18502 1104 1412 2541 1113 1347 1429 107 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.110504 140334737692480 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.111601 140334737692480 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.112461 140334737692480 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:52:56.116647 140334737692480 glue.py:119] *** Example ***\n",
      "I1011 13:52:56.117207 140334737692480 glue.py:120] guid: 2223\n",
      "I1011 13:52:56.117773 140334737692480 glue.py:121] input_ids: 101 2061 117 1150 1125 3421 16042 4290 1121 1201 1104 1344 1892 2997 117 1452 1120 14157 1116 118 22986 3875 1945 1213 130 131 1476 170 119 182 119 117 1163 2618 13105 20642 27776 119 102 2061 117 1150 1125 16042 4290 1121 1201 1104 1344 1892 2997 117 1125 1151 15819 17693 6834 1548 1105 1125 1151 2704 2200 1290 170 1347 6625 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.118458 140334737692480 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.119031 140334737692480 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.119538 140334737692480 glue.py:124] label: 0 (id = 0)\n",
      "I1011 13:52:56.122455 140334737692480 glue.py:119] *** Example ***\n",
      "I1011 13:52:56.123006 140334737692480 glue.py:120] guid: 2551\n",
      "I1011 13:52:56.123571 140334737692480 glue.py:121] input_ids: 101 1130 1103 8448 1692 117 11336 7272 19854 1163 1103 1329 1104 1886 1108 1136 107 11982 24423 107 1106 5515 1103 2755 112 188 14043 2199 1107 9531 119 102 11336 7272 19854 1724 1115 1103 1449 1108 1136 11982 24423 1106 5515 1103 2199 1107 4339 9531 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.124122 140334737692480 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.124665 140334737692480 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.125165 140334737692480 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:52:56.127865 140334737692480 glue.py:119] *** Example ***\n",
      "I1011 13:52:56.128417 140334737692480 glue.py:120] guid: 366\n",
      "I1011 13:52:56.128989 140334737692480 glue.py:121] input_ids: 101 1335 1661 7632 117 17185 1209 5152 1106 109 123 117 4645 1121 109 123 117 2260 119 102 3704 2134 1651 1209 1267 1147 17185 3606 1118 109 3127 1106 109 123 117 4645 1137 1367 3029 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.129538 140334737692480 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.130181 140334737692480 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.130697 140334737692480 glue.py:124] label: 1 (id = 1)\n",
      "I1011 13:52:56.133329 140334737692480 glue.py:119] *** Example ***\n",
      "I1011 13:52:56.133873 140334737692480 glue.py:120] guid: 416\n",
      "I1011 13:52:56.134514 140334737692480 glue.py:121] input_ids: 101 107 6983 112 188 170 1363 2564 117 107 16785 1163 117 5321 131 107 6983 1110 1690 1103 4185 1297 1104 1103 1203 1365 8765 119 102 1124 1145 1163 18000 2254 1110 107 1690 1103 4185 1297 1104 170 1203 1365 8765 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.135062 140334737692480 glue.py:122] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.135599 140334737692480 glue.py:123] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1011 13:52:56.136107 140334737692480 glue.py:124] label: 0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 40\n",
    "\n",
    "# Prepare dataset for GLUE as a tf.data.Dataset instance\n",
    "train_dataset = glue_convert_examples_to_features(data[\"train\"], tokenizer, 128, \"mrpc\")\n",
    "train_dataset = train_dataset.shuffle(512).batch(BATCH_SIZE).repeat(-1).prefetch(8)\n",
    "\n",
    "valid_dataset = glue_convert_examples_to_features(data[\"validation\"], tokenizer, 128, \"mrpc\")\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1011 13:52:57.669071 140334737692480 configuration_utils.py:150] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/jovyan/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1011 13:52:57.671084 140334737692480 configuration_utils.py:167] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1011 13:52:58.656917 140334737692480 modeling_tf_utils.py:256] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-tf_model.h5 from cache at /home/jovyan/.cache/torch/transformers/54c7ddffbd4d74d7592fac0cca93a6542cfee71482507625c277ddd4c6b7d41c.908e74db1113031d6827eb22808cf370b0aeded6e6ac20d0f07af0a334e195cc.h5\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, \"dynamic\")\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
    "model.compile(optimizer=opt,\n",
    "              loss=loss,\n",
    "              metrics=[acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_callback = TimeHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 91 steps, validate for 10 steps\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 89s 976ms/step - loss: 0.5511 - accuracy: 0.7264\n",
      "Epoch 2/4\n",
      "91/91 [==============================] - 17s 185ms/step - loss: 0.2914 - accuracy: 0.8848\n",
      "Epoch 3/4\n",
      "91/91 [==============================] - 59s 648ms/step - loss: 0.1227 - accuracy: 0.9581 - val_loss: 0.4197 - val_accuracy: 0.8725\n",
      "Epoch 4/4\n",
      "91/91 [==============================] - 13s 144ms/step - loss: 0.0486 - accuracy: 0.9862\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=4, steps_per_epoch=train_examples//BATCH_SIZE,\n",
    "                    validation_data=valid_dataset, validation_steps=valid_examples//BATCH_SIZE,\n",
    "                    validation_freq=3, callbacks=[time_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Examples/s: 279.0\n"
     ]
    }
   ],
   "source": [
    "epoch_time = min(time_callback.times)\n",
    "egs_per_sec = train_examples//epoch_time\n",
    "\n",
    "print(\"Peak Examples/s:\", egs_per_sec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
