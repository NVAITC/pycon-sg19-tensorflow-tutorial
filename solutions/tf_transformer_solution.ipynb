{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"tf_transformer_solution.ipynb","provenance":[],"collapsed_sections":["NWGze6qCm6Pu"],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NWGze6qCm6Pu","colab_type":"text"},"source":["## Setup\n","\n","This section contains supplementary information, functions, and installs required packages."]},{"cell_type":"code","metadata":{"id":"2Z_LEdIbm6Pv","colab_type":"code","colab":{}},"source":["!pip install tensorflow-gpu==2.0 tensorflow_datasets gpustat transformers -Uq"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FWiixEDBm6Px","colab_type":"text"},"source":["**About**\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/6/6d/Nvidia_image_logo.svg/200px-Nvidia_image_logo.svg.png\" width=\"90px\" align=\"right\" style=\"margin-right: 0px;\">\n","\n","This notebook is put together by Timothy Liu (`timothyl@nvidia.com`) for the [**PyCon SG**](https://pycon.sg/) 2019 tutorial on [**Improving Deep Learning Performance in TensorFlow**](https://github.com/NVAITC/pycon-sg19-tensorflow-tutorial).\n","\n","**Acknowledgements**\n","\n","* This notebook uses some materials adapted from TensorFlow documentation.\n","* This notebook uses the [HuggingFace Transformers library](https://github.com/huggingface/transformers).\n","* This notebook uses the [GLUE (MRPC) Dataset](https://gluebenchmark.com/) ([TensorFlow Datasets page](https://www.tensorflow.org/datasets/catalog/glue)).\n","\n","**Dataset Citation**\n","\n","```\n","@inproceedings{wang2019glue,\n","  title={ {GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n","  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n","  note={In the Proceedings of ICLR.},\n","  year={2019}\n","}\n","```"]},{"cell_type":"code","metadata":{"id":"got-iOfem6Py","colab_type":"code","colab":{}},"source":["import tensorflow.compat.v2 as tf\n","import tensorflow_datasets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LJMHzkWQm6P0","colab_type":"code","colab":{}},"source":["import time\n","\n","class TimeHistory(tf.keras.callbacks.Callback):\n","    def on_train_begin(self, logs={}):\n","        self.times = []\n","    def on_epoch_begin(self, epoch, logs={}):\n","        self.epoch_time_start = time.time()\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.times.append(time.time() - self.epoch_time_start)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bpOFAo4Km6P2","colab_type":"text"},"source":["# Sequence Classification with BERT in TF 2.0"]},{"cell_type":"code","metadata":{"id":"WufuRjQxp9h_","colab_type":"code","colab":{}},"source":["!gpustat"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sr25k7aNm6P2","colab_type":"code","colab":{}},"source":["# enable XLA\n","tf.config.optimizer.set_jit(True)\n","\n","# enable AMP via tf.config\n","tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V1Lz61HGm6P4","colab_type":"text"},"source":["## Load BERT Tokenizer"]},{"cell_type":"code","metadata":{"id":"tjMRDhSxm6P5","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"saAtsXk-m6P7","colab_type":"text"},"source":["## Input Pipeline"]},{"cell_type":"markdown","metadata":{"id":"cvmttt3mm6P7","colab_type":"text"},"source":["### Load Dataset"]},{"cell_type":"code","metadata":{"id":"FyaLd5x7m6P8","colab_type":"code","outputId":"a349e397-a488-405c-d6bf-53562f87f377","colab":{}},"source":["data, info = tensorflow_datasets.load(\"glue/mrpc\", with_info=True)\n","\n","train_examples = info.splits[\"train\"].num_examples\n","valid_examples = info.splits[\"validation\"].num_examples"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:absl:Overwrite dataset info from restored data version.\n","INFO:absl:Reusing dataset glue (/home/jovyan/tensorflow_datasets/glue/mrpc/0.0.2)\n","INFO:absl:Constructing tf.data.Dataset for split None, from /home/jovyan/tensorflow_datasets/glue/mrpc/0.0.2\n","WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"KCMkgYi5m6P-","colab_type":"text"},"source":["## Build Input Pipeline"]},{"cell_type":"code","metadata":{"id":"a-tl2kZEm6P-","colab_type":"code","colab":{}},"source":["from transformers import glue_convert_examples_to_features\n","\n","BATCH_SIZE = 40\n","\n","# Prepare dataset for GLUE as a tf.data.Dataset instance\n","train_dataset = glue_convert_examples_to_features(data[\"train\"], tokenizer, 128, \"mrpc\")\n","train_dataset = train_dataset.shuffle(512).batch(BATCH_SIZE).repeat(-1).prefetch(8)\n","\n","valid_dataset = glue_convert_examples_to_features(data[\"validation\"], tokenizer, 128, \"mrpc\")\n","valid_dataset = valid_dataset.batch(BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JqgFrbdbm6QA","colab_type":"text"},"source":["## Build BERT Model"]},{"cell_type":"markdown","metadata":{"id":"3yh2myknm6QB","colab_type":"text"},"source":["### Load Pre-trained BERT Model"]},{"cell_type":"code","metadata":{"id":"xpEvDnxum6QB","colab_type":"code","colab":{}},"source":["from transformers import TFBertForSequenceClassification\n","\n","model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvnCMjUzm6QD","colab_type":"code","colab":{}},"source":["opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n","# do loss scaling for optimizer\n","opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, \"dynamic\")\n","\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","acc = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n","model.compile(optimizer=opt,\n","              loss=loss,\n","              metrics=[acc])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TU_GlzZom6QF","colab_type":"text"},"source":["## Train BERT Model"]},{"cell_type":"code","metadata":{"id":"0p2POI4um6QF","colab_type":"code","colab":{}},"source":["time_callback = TimeHistory()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXXUn0sem6QH","colab_type":"code","outputId":"08bcdf53-a763-4ec1-bb69-0646efc5414a","colab":{}},"source":["history = model.fit(train_dataset, epochs=4, steps_per_epoch=train_examples//BATCH_SIZE,\n","                    validation_data=valid_dataset, validation_steps=valid_examples//BATCH_SIZE,\n","                    validation_freq=3, callbacks=[time_callback])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train for 91 steps, validate for 10 steps\n","Epoch 1/4\n"],"name":"stdout"},{"output_type":"stream","text":["/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["91/91 [==============================] - 101s 1s/step - loss: 0.6166 - accuracy: 0.6676\n","Epoch 2/4\n","91/91 [==============================] - 32s 354ms/step - loss: 0.4064 - accuracy: 0.8162\n","Epoch 3/4\n","91/91 [==============================] - 72s 787ms/step - loss: 0.2176 - accuracy: 0.9154 - val_loss: 0.5116 - val_accuracy: 0.8600\n","Epoch 4/4\n","91/91 [==============================] - 29s 315ms/step - loss: 0.0952 - accuracy: 0.9666\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pzy-LYBNm6QJ","colab_type":"code","outputId":"97a91fe5-d23c-4131-dd4e-7483aa219e14","colab":{}},"source":["epoch_time = min(time_callback.times)\n","egs_per_sec = train_examples//epoch_time\n","\n","print(\"Peak Examples/s:\", egs_per_sec)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Peak Examples/s: 128.0\n"],"name":"stdout"}]}]}